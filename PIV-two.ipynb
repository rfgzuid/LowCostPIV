{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-03T09:52:44.114494Z",
     "start_time": "2024-05-03T09:52:30.923891Z"
    }
   },
   "source": [
    "# %matplotlib widget\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import scipy.signal\n",
    "import scipy.ndimage\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\"\n",
    "sys.path.append(\"../../\")\n",
    "import helpers\n",
    "import glm\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T09:53:40.112452Z",
     "start_time": "2024-05-03T09:53:39.859741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def moving_window_array(array: torch.Tensor, window_size, overlap) -> torch.Tensor:\n",
    "    shape = array.shape\n",
    "    strides = (\n",
    "        shape[-1] * (window_size - overlap),\n",
    "        (window_size - overlap),\n",
    "        shape[-1],\n",
    "        1\n",
    "    )\n",
    "    shape = (\n",
    "        int((shape[-2] - window_size) / (window_size - overlap)) + 1,\n",
    "        int((shape[-1] - window_size) / (window_size - overlap)) + 1,\n",
    "        window_size,\n",
    "        window_size,\n",
    "    )\n",
    "    return torch.as_strided(\n",
    "        array, size=shape, stride=strides)"
   ],
   "id": "183f93df468c70c5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T09:53:44.926623Z",
     "start_time": "2024-05-03T09:53:44.712938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def index_min(lst):\n",
    "    index = lst.argmin()\n",
    "    col = lst.shape[1]\n",
    "    return index//col, index % col  # row, col"
   ],
   "id": "4c15d1e8a63714c9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T09:53:47.154205Z",
     "start_time": "2024-05-03T09:53:46.872055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "testing_0 = helpers.imread_normalized_float_grayscale(os.path.join(\"test\", \"0.jpg\"))\n",
    "testing_0 = np.where(testing_0 > 0.5, 1.0, 0.0)  # TEMPORARY, TO MAKE TEST MORE IDEAL\n",
    "testing_1 = helpers.imread_normalized_float_grayscale(os.path.join(\"test\", \"1.jpg\"))\n",
    "testing_1 = np.where(testing_1 > 0.5, 1.0, 0.0)  # TEMPORARY, TO MAKE TEST MORE IDEAL\n",
    "testtest_0 = np.array(np.split(np.arange(64), 8))\n",
    "testtest_1 = np.array(np.split(np.arange(64), 8)) - 1"
   ],
   "id": "38384a7a83c8fd6c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T09:53:49.327536Z",
     "start_time": "2024-05-03T09:53:48.917279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test0 = helpers.imread_normalized_float_grayscale(os.path.join(\"plume simulation\", \"00101.jpg\"))\n",
    "test1 = helpers.imread_normalized_float_grayscale(os.path.join(\"plume simulation\", \"00102.jpg\"))"
   ],
   "id": "97ee1f27100eb8a3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T09:54:39.322242Z",
     "start_time": "2024-05-03T09:53:52.924309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assumptions for simple version: ignoring restrictions and bug checks, assuming window size fits into img with no remainder, overlap is strictly less than window size, images are numpy arrays and perfect squares\n",
    "def calculate(img1, img2, window_size, overlap):\n",
    "    # split img1 into windows, 3d array, with all possible overlaps:\n",
    "    img1_windowed = moving_window_array(torch.from_numpy(img1), window_size, overlap)\n",
    "    img2_windowed = moving_window_array(torch.from_numpy(img2), window_size, overlap)\n",
    "    # Check correlation from 1 image to next one, for each window, to get movement of each patch.\n",
    "    # Searching whole image for correlation for each window is redundant, only searching for two windows across. Assumption: Each image split into at least a 2x2 grid of windows.\n",
    "    offset = 4  # for now\n",
    "    window_dim = int(img2_windowed.shape[0])\n",
    "    vector_field_shape = list((*img2_windowed.shape[:2], 4))\n",
    "    vector_field = np.zeros(vector_field_shape)\n",
    "    for row_1, window_1_row in enumerate(img1_windowed):\n",
    "            for col_1, window_1 in enumerate(window_1_row):\n",
    "                row_min = max((row_1-offset), 0)\n",
    "                row_max = min((row_1+offset) + 1, window_dim)\n",
    "                col_min = max((col_1-offset), 0)\n",
    "                col_max = min((col_1+offset) + 1, window_dim)\n",
    "                rel_windows_2 = img2_windowed[row_min:row_max, col_min:col_max, :, : ]\n",
    "                rel_diffs = np.zeros(rel_windows_2.shape[:2])\n",
    "                for row_2, rel_row_2 in enumerate(rel_windows_2):\n",
    "                    for col_2, rel_wind_2 in enumerate(rel_row_2):\n",
    "                        rel_diffs[row_2,col_2] = torch.sum(torch.abs(window_1 - rel_wind_2)).item() / (rel_windows_2.shape[0] * rel_windows_2.shape[1])\n",
    "                smallest_rel_index = index_min(rel_diffs)\n",
    "                wind_2_abs_loc = np.array((row_min, col_min)) + smallest_rel_index\n",
    "                vect = wind_2_abs_loc - (row_1, col_1)\n",
    "                vect_loc = (row_1 * (window_size - overlap) + window_size // 2, (col_1 * (window_size - overlap) + window_size // 2))\n",
    "                vector_field[row_1, col_1, :] = np.array((*vect, *vect_loc))\n",
    "    return np.array(vector_field)\n",
    "bc = calculate(testing_0, testing_1, 32, 31)\n"
   ],
   "id": "8fa4f4c0ce9e1f93",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T09:54:39.675716Z",
     "start_time": "2024-05-03T09:54:39.353158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_velocity(img, field):\n",
    "    vx, vy, x, y =  np.reshape(field, (field.shape[0] * field.shape[1], 4)).T\n",
    "        \n",
    "            # new_x = x/piv_gen._scale\n",
    "            # new_y = y/piv_gen._scale\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.quiver(x, y, vx, vy, color='red')\n",
    "    plt.show()"
   ],
   "id": "294463bf478e47e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T09:56:47.201264Z",
     "start_time": "2024-05-03T09:54:40.258695Z"
    }
   },
   "cell_type": "code",
   "source": "plot_velocity(testing_0, bc)",
   "id": "f18af34808bdb514",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#### OLD VERSION ###\n",
    "# img2_4d = img2_windowed.reshape(window_dim, window_dim, img2_windowed.shape[-2], img2_windowed.shape[-1])\n",
    "#     vector_field_shape = list((*img2_4d.shape[:2], 2))\n",
    "#     vector_field = np.zeros(vector_field_shape)\n",
    "#     for i, window_1 in enumerate(img1_windowed):\n",
    "#         row = i // window_dim\n",
    "#         col = i % window_dim\n",
    "#         rel_windows_2 = img2_4d[max((row-4),0):min((row+4) + 1,window_dim), max((col-4),0):min((col+4) + 1,window_dim), :, : ]\n",
    "#         rel_diffs = np.zeros(rel_windows_2.shape[:2])\n",
    "#         for j, rel_cols_2 in enumerate(rel_windows_2):\n",
    "#             for k, rel_wind_2 in enumerate(rel_cols_2):\n",
    "#                 rel_diffs[j,k] = torch.sum(torch.abs(window_1 - rel_wind_2)).item() / (window_size ** 2)\n",
    "#         \n",
    "#         vector_field[row, col, :] = index_min(rel_diffs)\n",
    "#     return np.array(vector_field)\n",
    "# bc = calculate(testing_0, testing_1, 64, 61)\n",
    "# WINDOWING FUNCTIONS\n",
    "# assuming for now that window size fits perfectly into img, and img is 2d np array perfect square  \n",
    "# def windowed_old(img, window_size):\n",
    "#     return np.lib.stride_tricks.as_strided(img, shape=(int(img.shape[0] / window_size), int(img.shape[1] / window_size), window_size, window_size), strides =(img.strides[0] * window_size, img.strides[1] * window_size, img.strides[0], img.strides[1]) , writeable=False)\n",
    "\n",
    "# TODO: UNUSED CODE, IGNORE THIS CELL\n",
    "# # Just to visualize images\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.axis(\"off\")\n",
    "# ax.set_title(\"Projected points\")\n",
    "# ax.imshow(windowed(testing_0, 8).reshape((128,128)), cmap=\"gray\")\n",
    "# # ax.imshow(testing_0, cmap=\"gray\")\n",
    "# \n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "# print(testing_0)\n",
    "\n",
    "#     # return img.reshape((int(img.shape[0] / window_size), int(img.shape[1] / window_size), window_size, window_size))\n",
    "#     \n",
    "# def windowed(img, window_size):\n",
    "#     return ressample(img, window_size)\n",
    "# def ressample(arr, N):\n",
    "#     A = []\n",
    "#     for v in np.vsplit(arr, arr.shape[0] // N):\n",
    "#         A.extend([*np.hsplit(v, arr.shape[0] // N)])\n",
    "#     return np.array(A)\n",
    "# \n",
    "# \n",
    "        # up_offs_row = max(row - window_size // (window_size - overlap) - 1, 0)\n",
    "        # down_offs_row = min(row + window_size // (window_size - overlap) + 1, window_dim)\n",
    "        # left_offs_col = max(col - window_size // (window_size - overlap) - 1, 0)\n",
    "        # right_offs_col = min(col + window_size // (window_size - overlap) + 1, window_dim)\n",
    "        # current_wind_2 = img2_4d[left_offs_col:right_offs_col, up_offs_row:down_offs_row, :, :]\n",
    "        # testtesttorch = torch.from_numpy(testtest)\n",
    "# print(testtesttorch)\n",
    "# print(testtesttorch.shape)\n",
    "# print(moving_window_array(testtesttorch, 4, 3).shape)\n"
   ],
   "id": "394b89bf0861455"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
